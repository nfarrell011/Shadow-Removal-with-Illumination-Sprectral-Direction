{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import os  \n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nelsonfarrell/Documents/Northeastern/7180/projects/spectral_ratio\n"
     ]
    }
   ],
   "source": [
    "path = Path(os.getcwd())\n",
    "parent = path.parent\n",
    "parent = str(parent)\n",
    "path = str(path)\n",
    "print(path)\n",
    "sys.path.insert(1, path)\n",
    "sys.path.insert(1, parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader_dev.dataset_generator_class import ImageDatasetGenerator\n",
    "from models.CvT_model import CvT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms -- We can add augmentations here\n",
    "transform_images = transforms.Compose([ \n",
    "                        transforms.ToTensor()       \n",
    "                        #transforms.Normalize(mean = mean, std = std)\n",
    "                                    ])\n",
    "\n",
    "transform_guidance = transforms.Compose([ \n",
    "                        transforms.ToTensor()\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assertion Passed!!! We have the same number of images and ISD maps.\n",
      "Assertion Passed!!! We have the same number of images and ISD maps.\n",
      "Assertion Passed!!! We have the same number of images and ISD maps.\n"
     ]
    }
   ],
   "source": [
    "# Folder paths\n",
    "image_folder = \"/Users/nelsonfarrell/Documents/Northeastern/7180/projects/spectral_ratio/training_data/training_images_cropped\"\n",
    "isd_map_folder = \"/Users/nelsonfarrell/Documents/Northeastern/7180/projects/spectral_ratio/training_data/training_isds_cropped\"\n",
    "\n",
    "# Create dataset\n",
    "dataset = ImageDatasetGenerator(image_folder, \n",
    "                                isd_map_folder, \n",
    "                                split = None, \n",
    "                                val_size = 0.2, \n",
    "                                random_seed = 42, \n",
    "                                transform_images = transform_images, \n",
    "                                transform_guidance = transform_guidance)\n",
    "\n",
    "# Create dataset\n",
    "train_dataset = ImageDatasetGenerator(image_folder, \n",
    "                                      isd_map_folder, \n",
    "                                      split = \"train\", \n",
    "                                      val_size = 0.2, \n",
    "                                      random_seed = 42, \n",
    "                                      transform_images = transform_images, \n",
    "                                      transform_guidance = transform_guidance)\n",
    "\n",
    "# Create dataset\n",
    "val_dataset = ImageDatasetGenerator(image_folder, \n",
    "                                    isd_map_folder, \n",
    "                                    split = \"val\", \n",
    "                                    val_size = 0.2, \n",
    "                                    random_seed = 42, \n",
    "                                    transform_images = transform_images, \n",
    "                                    transform_guidance = transform_guidance)\n",
    "\n",
    "# Create dataloader\n",
    "# Shuffle equals false for now for testing\n",
    "# drop last creates only full batches\n",
    "dataloader = DataLoader(val_dataset, batch_size = 4, shuffle = False, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering embedding: Patch Size: 7 -- Stride: 4 -- Embedding Dims 64\n",
      "Entering embedding: Patch Size: 3 -- Stride: 2 -- Embedding Dims 192\n",
      "Entering embedding: Patch Size: 3 -- Stride: 2 -- Embedding Dims 384\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'  \n",
    "embed_size = 64\n",
    "num_class = 10\n",
    "model = CvT(embed_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/298 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/298 [00:01<06:13,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 2/298 [00:02<05:35,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 3/298 [00:03<05:20,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 4/298 [00:04<05:10,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 5/298 [00:05<05:07,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 6/298 [00:06<05:06,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 7/298 [00:07<05:02,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 8/298 [00:08<04:59,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 9/298 [00:09<04:55,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 10/298 [00:10<04:53,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 11/298 [00:11<04:53,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 12/298 [00:12<04:50,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 13/298 [00:13<04:48,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 14/298 [00:14<04:48,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 15/298 [00:15<04:49,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 16/298 [00:16<04:48,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 17/298 [00:17<04:45,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 18/298 [00:18<04:45,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 19/298 [00:19<04:44,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 20/298 [00:20<04:44,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 21/298 [00:21<04:41,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 22/298 [00:22<04:40,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 23/298 [00:23<04:38,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 24/298 [00:24<04:37,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 25/298 [00:25<04:35,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 26/298 [00:26<04:35,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 27/298 [00:27<04:34,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 28/298 [00:28<04:34,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 29/298 [00:29<04:32,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 30/298 [00:30<04:30,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 31/298 [00:31<04:30,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 32/298 [00:32<04:29,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 33/298 [00:33<04:26,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 34/298 [00:34<04:25,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 35/298 [00:35<04:25,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 36/298 [00:36<04:24,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n",
      "Stage 3: Shape x: torch.Size([4, 384, 13, 13])\n",
      "After Stage 3 -> 2: torch.Size([4, 192, 27, 27])\n",
      "After Stage 2 -> 1: torch.Size([4, 64, 55, 55])\n",
      "After Stage 1 -> Original: torch.Size([4, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 37/298 [00:37<04:23,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X IN: torch.Size([4, 3, 224, 224])\n",
      "Shape X OUT: torch.Size([4, 3025, 64])\n",
      "Stage 1: Shape x: torch.Size([4, 64, 55, 55])\n",
      "Shape X IN: torch.Size([4, 64, 55, 55])\n",
      "Shape X OUT: torch.Size([4, 729, 192])\n",
      "Stage 2: Shape x: torch.Size([4, 192, 27, 27])\n",
      "Shape X IN: torch.Size([4, 192, 27, 27])\n",
      "Shape X OUT: torch.Size([4, 169, 384])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Parameters\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 4\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Assuming regression; adjust for classification if needed\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    # Training Step\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "        images, guidance_maps = batch\n",
    "        images, guidance_maps = images.to(device), guidance_maps.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, guidance_maps)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    print(f\"Training Loss: {train_loss:.4f}\")\n",
    "\n",
    "    # Validation Step\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "            images, guidance_maps = batch\n",
    "            images, guidance_maps = images.to(device), guidance_maps.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, guidance_maps)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "print(\"Training Complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b31d6a8ecfd6b48ec0cf9da67896692b418c4a39f70d4f1a3880fdc530a94b5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
