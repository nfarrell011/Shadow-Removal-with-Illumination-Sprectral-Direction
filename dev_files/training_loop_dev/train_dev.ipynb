{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################################################### Packages ###################################################################\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# class TrainViT:\n",
    "#     \"\"\"\n",
    "#     Class to pretrain the generator network\n",
    "#     \"\"\"\n",
    "#     def __init__(self, \n",
    "#                  image_size = 224, \n",
    "#                  batch_size = 32, \n",
    "#                  epochs = 100, \n",
    "#                  lr = 0.0002, \n",
    "#                  beta1 = 0.5, \n",
    "#                  beta2 = 0.999, \n",
    "#                  weight_decay=0, \n",
    "#                  loss = nn.CosineSimilarity(), \n",
    "#                  run = \"training_run\",\n",
    "#                  save_dir = '/results', \n",
    "#                  start_epoch = 0):\n",
    "#         \"\"\"\n",
    "#         Initializes class TrainViT: class with all default values.\n",
    "#         See methods to perform sets.\n",
    "#         \"\"\"\n",
    "#         self.image_size = image_size\n",
    "#         self.batch_size = batch_size\n",
    "#         self.lr = lr\n",
    "#         self.beta1 = beta1\n",
    "#         self.beta2 = beta2\n",
    "#         self.weight_decay = weight_decay\n",
    "#         self.loss = loss\n",
    "#         self.run = run\n",
    "#         self.save_dir = save_dir\n",
    "#         self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#         self.model = None\n",
    "#         self.optimizer = None\n",
    "#         self.scheduler = None\n",
    "\n",
    "#         self.start_epoch = start_epoch\n",
    "#         self.epochs = epochs\n",
    "#         self.avg_loss = 0\n",
    "\n",
    "#         self.train_ds = None\n",
    "#         self.val_ds = None\n",
    "#         self.train_dl = None\n",
    "#         self.val_dl = None\n",
    "\n",
    "#         self.train_loss = []\n",
    "#         self.val_loss = []\n",
    "\n",
    "#         self.val_paths = None\n",
    "#         self.train_paths = None\n",
    "\n",
    "#     def set_train_and_val_paths(self, data_dir:str, num_images:int) -> None:\n",
    "#         \"\"\"\n",
    "#         Implement me\n",
    "#         \"\"\"\n",
    "#         self.train_paths, self.val_paths = \n",
    "        \n",
    "#     def set_model(self, model:callable = None) -> None:\n",
    "#         \"\"\"\n",
    "#         Set the generator model and optimizer, default is to use a U-Net with a ResNet18 backbone\n",
    "#         \"\"\"\n",
    "#         self.model = model\n",
    "\n",
    "#     def load_state(self, path_to_checkpoint:str) -> None:\n",
    "#         \"\"\"\n",
    "#         Loads a previous model state\n",
    "#         \"\"\"\n",
    "#         try:\n",
    "#             checkpoint = torch.load(path_to_checkpoint)\n",
    "#             self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "#             self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#             self.start_epoch = checkpoint['epoch']\n",
    "#             self.avg_loss = checkpoint['loss']\n",
    "#             print(f\"Model state loaded successfully!\")\n",
    "#         except FileNotFoundError as e:\n",
    "#             print(\"Error loading generator weights!\")\n",
    "#         return\n",
    "\n",
    "#     def set_data_loaders(self, perform_checks:bool = True) -> None:\n",
    "#         \"\"\"\n",
    "#         Set up the dataloaders\n",
    "#         \"\"\"\n",
    "#         self.train_ds = IsdDataSet(self.batch_size, paths = self.train_paths, split = \"train\")\n",
    "#         self.val_ds = IsdDataSet(self.batch_size, paths = self.val_paths, split = \"val\")\n",
    "#         self.train_dl = DataLoader(self.train_ds, batch_size = self.batch_size)\n",
    "#         self.val_dl = DataLoader(self.val_ds, batch_size = self.batch_size)\n",
    "\n",
    "#         if perform_checks:\n",
    "#             data = next(iter(self.train_dl))\n",
    "#             imgs, isds = data['L'], data['ab']\n",
    "#             assert imgs.shape == isds.shape \n",
    "#             print(f\" Image data dims: {imgs.shape} \\nISD data dims: {isds.shape}\")\n",
    "#             print(len(self.train_dl), len(self.val_dl))\n",
    "\n",
    "#         return\n",
    "\n",
    "#     def train_loop(self, epoch) -> None:\n",
    "#         \"\"\"\n",
    "#         Performs the train loop tracking train loss\n",
    "#         \"\"\"\n",
    "#         epoch_train_loss = 0\n",
    "#         num_batches = 0\n",
    "\n",
    "#         # Train Loop\n",
    "#         pbar = tqdm(self.train_dl, desc=f\"Training Epoch {self.start_epoch}/{self.start_epoch + self.epochs}\")\n",
    "#         for i, data in enumerate(pbar):\n",
    "#             imgs, isds = data[\"imgs\"], data[\"isds\"]\n",
    "#             imgs, isds = imgs.to(self.device), isds.to(self.device)\n",
    "    \n",
    "#             # Train the generator\n",
    "#             self.model.train()\n",
    "#             self.optimizer.zero_grad()\n",
    "#             model_output = self.model(imgs)\n",
    "    \n",
    "#             LOSS = self.loss(model_output, isds) \n",
    "#             LOSS.backward()\n",
    "#             self.optimizer.step()\n",
    "    \n",
    "#             # Accumulate losses\n",
    "#             epoch_train_loss += LOSS.item()\n",
    "#             num_batches += 1\n",
    "    \n",
    "#             # Update progress bar with current loss values\n",
    "#             pbar.set_postfix(G_loss=LOSS.item())\n",
    "    \n",
    "#         # Average losses for the epoch\n",
    "#         avg_train_loss = epoch_train_loss / num_batches\n",
    "#         self.train_loss.append(avg_train_loss)\n",
    "#         print(f\"The average loss for epoch: {epoch} - {avg_train_loss}\")\n",
    "    \n",
    "#         self.scheduler.step(avg_train_loss)\n",
    "\n",
    "#     def val_loop(self, epoch) -> None:\n",
    "#         \"\"\"\n",
    "#         Performs the val loop tracking val loss\n",
    "#         \"\"\"\n",
    "#         with torch.no_grad():\n",
    "#             num_batches = 0\n",
    "#             epoch_val_loss = 0\n",
    "#             self.model.eval()\n",
    "            \n",
    "#             pbar = tqdm(self.val_dl, desc=f\"Validation Epoch {self.start_epoch}/{self.start_epoch + self.epochs}\")\n",
    "#             for i, data in enumerate(pbar):\n",
    "#                 imgs, isds = data[\"imgs\"], data[\"isds\"]\n",
    "#                 imgs, isds = imgs.to(self.device), isds.to(self.device)\n",
    "    \n",
    "#                  # Evaluate the generator\n",
    "#                 model_output = self.model(imgs)\n",
    "#                 LOSS = self.loss(model_output, isds) \n",
    "        \n",
    "#                 # Accumulate losses\n",
    "#                 epoch_val_loss += LOSS.item()\n",
    "#                 num_batches += 1\n",
    "        \n",
    "#                 # Update progress bar with current loss values\n",
    "#                 pbar.set_postfix(G_loss=LOSS.item())\n",
    "    \n",
    "#                 # Create the directory to save iamges in\n",
    "#                 image_save_dir = f\"{str(Path.cwd())}/training_runs/{self.run}/val_images/\"\n",
    "#                 os.makedirs(image_save_dir, exist_ok=True)\n",
    "#                 image_save_path = image_save_dir + f\"epoch_{epoch}.png\"\n",
    "                \n",
    "#                 if epoch % 10 == 0:\n",
    "#                     self.plot_batch(imgs, model_output, isds, show = False, save_path = image_save_path)\n",
    "        \n",
    "#         # Calculate average validation loss\n",
    "#         avg_val_loss = epoch_val_loss / num_batches\n",
    "#         self.val_loss.append(avg_val_loss)\n",
    "#         print(f\"Avg Validation Loss: {avg_val_loss}\")\n",
    "#         return\n",
    "\n",
    "#     def plot_losses(self, epoch) -> None:\n",
    "#         \"\"\"\n",
    "#         Generates and saves loss versus epoch plot\n",
    "#         \"\"\"\n",
    "#         # Create fig\n",
    "#         figs_save_dir = f\"{str(Path.cwd())}/training_runs/{self.run}/loss_figs/\"\n",
    "#         os.makedirs(figs_save_dir, exist_ok=True)\n",
    "#         figs_save_path = figs_save_dir + f\"epoch_{epoch}.png\"\n",
    "                \n",
    "#         # Ensure the directory exists\n",
    "#         epoch_range = range(self.start_epoch, epoch + 1)\n",
    "#         plt.plot(epoch_range, self.train_loss_generator, c = \"b\", label = \"Train Loss\")\n",
    "#         plt.plot(epoch_range, self.val_loss_generator, c = \"r\", label = \"Val Loss\")\n",
    "#         plt.legend()\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(figs_save_path)\n",
    "#         plt.close\n",
    "\n",
    "#     def save_model_state(self, epoch:int) -> None:\n",
    "#         \"\"\"\n",
    "#         Saves the current model state\n",
    "#         \"\"\"\n",
    "#         # Path to model weights location \n",
    "#         state_save_dir = f\"{self.save_dir}/model_states\"\n",
    "    \n",
    "#         # Ensure the directory exists\n",
    "#         os.makedirs(state_save_dir, exist_ok=True)\n",
    "    \n",
    "#         # Update path with file name\n",
    "#         state_save_path = os.path.join(state_save_dir, f'checkpoint_epoch_{epoch}.pth')\n",
    "    \n",
    "#         # Save the model weights\n",
    "#         torch.save({\n",
    "#             'epoch': epoch,\n",
    "#             'model_state_dict': self.model.state_dict(),\n",
    "#             'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "#             'loss': self.train_loss_generator[-1],\n",
    "#         }, state_save_path)\n",
    "#         print(f\"Model state saved to: {state_save_path}\")\n",
    "\n",
    "    \n",
    "#     def save_config(self, config, file_name=\"config.yaml\"):\n",
    "#         \"\"\"\n",
    "#         Save the configuration dictionary as a YAML file.\n",
    "\n",
    "#         Args:\n",
    "#             config (dict): The configuration parameters to save.\n",
    "#             file_name (str): The name of the YAML file. Defaults to \"config.yaml\".\n",
    "#         \"\"\"\n",
    "#         save_path = os.path.join(self.save_dir, file_name)\n",
    "#         try:\n",
    "#             with open(save_path, \"w\") as yaml_file:\n",
    "#                 yaml.dump(config, yaml_file, default_flow_style=False)\n",
    "#             print(f\"Configuration saved to {save_path}\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error saving configuration: {e}\")\n",
    "        \n",
    "#     def train_model(self) -> None:\n",
    "#         \"\"\"\n",
    "#         Trains the model\n",
    "#         \"\"\"\n",
    "#         for epoch in range(self.start_epoch, self.start_epoch + self.epochs):\n",
    "#             self.train_loop(epoch)\n",
    "#             self.val_loop(epoch)\n",
    "#             if epoch % 10 == 1:\n",
    "#                 self.plot_losses()\n",
    "#                 self.save_model_state()\n",
    "        \n",
    "#     def set_optimizer(self, model_params) -> None:\n",
    "#         \"\"\"\n",
    "#         Method to set up the optimizer\n",
    "#         \"\"\"\n",
    "#         self.optimizer = torch.optim.Adam(model_params, lr=self.lr, betas=(self.beta1, self.beta2), weight_decay=self.weight_decay)\n",
    "\n",
    "#     def set_scheduler(self) -> None:\n",
    "#         \"\"\"\n",
    "#         Method to set up the scheduler\n",
    "#         \"\"\"\n",
    "#         raise NotImplementedError\n",
    "\n",
    "# print(\"This works!!\")\n",
    "# if __name__ == \"__main__\":\n",
    "#     pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Param YAML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General training configuration\n",
    "checkpoint_path: null       # Path to checkpoint file if loading a previous state\n",
    "load_previous_state: false  # Whether to load a previous state\n",
    "data_dir: \"path/to/data\"    # Directory containing .tif images\n",
    "num_images: 1000            # Number of images to use for training\n",
    "size: 224                   # Image size\n",
    "batch_size: 32              # Batch size for training\n",
    "epochs: 101                 # Number of epochs for training\n",
    "lr: 0.0002                  # Learning rate\n",
    "beta1: 0.5                  # Beta1 for Adam optimizer\n",
    "beta2: 0.999                # Beta2 for Adam optimizer\n",
    "run: \"test_run_01\"          # Run name for logging and saving checkpoints\n",
    "save_dir: \"/results/test_run_01\"  # Explicitly set save directory\n",
    "start_epoch: 0              # Starting epoch\n",
    "\n",
    "# Optimizer configuration\n",
    "optimizer:\n",
    "  type: \"Adam\"              # Type of optimizer (e.g., \"Adam\", \"SGD\", etc.)\n",
    "  lr: 0.0002                # Learning rate\n",
    "  weight_decay: 0.0001      # Weight decay (L2 regularization)\n",
    "  beta1: 0.5                # Beta1 parameter for Adam\n",
    "  beta2: 0.999              # Beta2 parameter for Adam\n",
    "  momentum: null            # Momentum (only used for optimizers like SGD)\n",
    "\n",
    "# Scheduler configuration (choose one)\n",
    "scheduler:\n",
    "  use_scheduler: true       # Whether to use a learning rate scheduler\n",
    "  type: \"StepLR\"            # Type of scheduler (\"StepLR\", \"ReduceLROnPlateau\", etc.)\n",
    "  params:                   # Scheduler-specific parameters\n",
    "    step_size: 10           # For StepLR\n",
    "    gamma: 0.1              # For StepLR\n",
    "\n",
    "# Alternative scheduler configurations (comment out the above and uncomment one of these if needed)\n",
    "# scheduler:\n",
    "#   use_scheduler: true\n",
    "#   type: \"ReduceLROnPlateau\"\n",
    "#   params:\n",
    "#     mode: \"min\"\n",
    "#     factor: 0.1\n",
    "#     patience: 5\n",
    "#     threshold: 0.01\n",
    "#     cooldown: 2\n",
    "\n",
    "# scheduler:\n",
    "#   use_scheduler: true\n",
    "#   type: \"CosineAnnealingLR\"\n",
    "#   params:\n",
    "#     T_max: 50\n",
    "#     eta_min: 1e-6\n",
    "\n",
    "# Pretrained settings\n",
    "pretrained:\n",
    "  checkpoint_path: null     # Path to checkpoint file if loading a previous state\n",
    "  load_model_state: false   # Whether to load the model state\n",
    "  load_optim_states: false  # Whether to load optimizer states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# import yaml\n",
    "\n",
    "# def load_optimizer_states(optimizer, config):\n",
    "#     \"\"\"\n",
    "#     Loads the optimizer states for generator and discriminator from the checkpoint\n",
    "#     if they exist and if the config specifies to do so.\n",
    "\n",
    "#     Args:\n",
    "#         optimizer (torch.optim.Optimizer): Optimizer\n",
    "#         checkpoint (dict): The loaded checkpoint containing model and optimizer states.\n",
    "#         config (dict): Configuration dictionary specifying whether to load optimizer states.\n",
    "\n",
    "#     Returns:\n",
    "#         None\n",
    "#     \"\"\"\n",
    "#     if config['pretrained']['checkpoint_path']:\n",
    "#         checkpoint_path = config['pretrained']['checkpoint_path']\n",
    "#         checkpoint = torch.load(checkpoint_path)\n",
    "        \n",
    "#     if config['pretrained']['load_optim_states']:\n",
    "#         try:\n",
    "#             if 'optimizer_state_dict' in checkpoint:\n",
    "#                 optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#             else:\n",
    "#                 print(\"Optimizer state dictionaries not found in checkpoint.\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error loading optimizer states: {e}\")\n",
    "\n",
    "#     return optimizer\n",
    "\n",
    "\n",
    "# # Load parameters from YAML\n",
    "# with open(\"config.yaml\", \"r\") as file:\n",
    "#     params = yaml.safe_load(file)\n",
    "\n",
    "# # Extract parameters\n",
    "# checkpoint_path = params.get(\"checkpoint_path\")\n",
    "# load_previous_state = params.get(\"load_previous_state\", False)\n",
    "# data_dir = params[\"data_dir\"]\n",
    "# paths = glob.glob(data_dir + \"/*.tif\")\n",
    "# num_images = params[\"num_images\"]\n",
    "# size = params[\"size\"]\n",
    "# batch_size = params[\"batch_size\"]\n",
    "# epochs = params[\"epochs\"]\n",
    "# lr = params[\"lr\"]\n",
    "# beta1 = params[\"beta1\"]\n",
    "# beta2 = params[\"beta2\"]\n",
    "# l1_loss = nn.L1Loss()\n",
    "# run = params[\"run\"]\n",
    "# save_dir = params[\"save_dir\"]\n",
    "# start_epoch = params[\"start_epoch\"]\n",
    "\n",
    "# # Select model\n",
    "# model = None  # Define or load your model here if needed\n",
    "# model_params = model.parameters()\n",
    "\n",
    "# # Train model\n",
    "# vit_trainer = TrainViT(size, batch_size, epochs, lr, beta1, beta2, l1_loss, run, start_epoch)\n",
    "# vit_trainer.set_train_and_val_paths(paths, num_images)\n",
    "# vit_trainer.set_data_loaders()\n",
    "# vit_trainer.set_model(model=model)\n",
    "# vit_trainer.set_optimizer(model_params=model_params)\n",
    "# if load_previous_state:\n",
    "#     vit_trainer.load_state(checkpoint_path)\n",
    "# vit_trainer.save_config(config=params)    \n",
    "# vit_trainer.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "from dataloader_dev import ImageDatasetGenerator\n",
    "\n",
    "class TrainViT:\n",
    "    \"\"\"\n",
    "    Class to pretrain the generator network with a Vision Transformer backbone.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 image_size=224,\n",
    "                 batch_size=32,\n",
    "                 epochs=100,\n",
    "                 lr=0.0002,\n",
    "                 beta1=0.5,\n",
    "                 beta2=0.999,\n",
    "                 weight_decay=0,\n",
    "                 loss=nn.CosineSimilarity(),\n",
    "                 run=\"training_run\",\n",
    "                 save_dir='/results',\n",
    "                 start_epoch=0):\n",
    "        \"\"\"\n",
    "        Initializes TrainViT class with default or user-provided values.\n",
    "        \"\"\"\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "\n",
    "        self.image_size = image_size\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.weight_decay = weight_decay\n",
    "        self.loss = loss\n",
    "        self.run = run\n",
    "        self.save_dir = save_dir\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.model = None\n",
    "        self.optimizer = None\n",
    "        self.scheduler = None\n",
    "\n",
    "        self.start_epoch = start_epoch\n",
    "        self.epochs = epochs\n",
    "        self.avg_loss = 0\n",
    "\n",
    "        self.train_ds = None\n",
    "        self.val_ds = None\n",
    "        self.train_dl = None\n",
    "        self.val_dl = None\n",
    "\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "\n",
    "        self.val_paths = None\n",
    "        self.train_paths = None\n",
    "\n",
    "    def set_train_and_val_paths(self, data_dir: str, num_images: int) -> None:\n",
    "        \"\"\"\n",
    "        Placeholder for setting training and validation paths.\n",
    "        \"\"\"\n",
    "        self.train_paths = os.path.join(data_dir, \"train\")\n",
    "        self.val_paths = os.path.join(data_dir, \"val\")\n",
    "        self.logger.info(f\"Train and val paths set: {self.train_paths}, {self.val_paths}\")\n",
    "\n",
    "    def set_model(self, model: callable = None) -> None:\n",
    "        \"\"\"\n",
    "        Sets the generator model.\n",
    "        \"\"\"\n",
    "        self.model = model.to(self.device)\n",
    "        self.logger.info(\"Model initialized.\")\n",
    "\n",
    "    def load_state(self, path_to_checkpoint: str) -> None:\n",
    "        \"\"\"\n",
    "        Loads a previous model state.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            checkpoint = torch.load(path_to_checkpoint, map_location=self.device)\n",
    "            self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            self.start_epoch = checkpoint['epoch']\n",
    "            self.avg_loss = checkpoint['loss']\n",
    "            self.logger.info(\"Model state loaded successfully.\")\n",
    "        except FileNotFoundError as e:\n",
    "            self.logger.error(f\"Error loading checkpoint: {e}\")\n",
    "        except KeyError as e:\n",
    "            self.logger.error(f\"Checkpoint is missing a key: {e}\")\n",
    "\n",
    "    def set_data_loaders(self, image_dir: str, isd_map_dir: str, perform_checks: bool = True) -> None:\n",
    "        \"\"\"\n",
    "        Sets up the dataloaders.\n",
    "\n",
    "        Args:\n",
    "            image_dir (str): Directory of training images.\n",
    "            isd_map_dir (str): Directory of isd maps corresponding to training images. \n",
    "            performs_check (bool): If True (default), will check that dataloader output.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # Transforms -- We can add augmentations here\n",
    "        transform_images = transforms.Compose([ \n",
    "                                transforms.ToTensor()       \n",
    "                                #transforms.Normalize(mean = mean, std = std)\n",
    "                                            ])\n",
    "\n",
    "        transform_guidance = transforms.Compose([ \n",
    "                                transforms.ToTensor()\n",
    "                                            ])\n",
    "        \n",
    "        # Create train split\n",
    "        self.train_ds = ImageDatasetGenerator(image_dir, \n",
    "                                            isd_map_dir, \n",
    "                                            split = \"train\", \n",
    "                                            val_size = 0.2, \n",
    "                                            random_seed = 42, \n",
    "                                            transform_images = transform_images, \n",
    "                                            transform_guidance = transform_guidance)\n",
    "        self.train_dl = DataLoader(self.train_ds, batch_size=self.batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "        # Create val split\n",
    "        self.val_ds = ImageDatasetGenerator(image_dir, \n",
    "                                            isd_map_dir, \n",
    "                                            split = \"val\", \n",
    "                                            val_size = 0.2, \n",
    "                                            random_seed = 42, \n",
    "                                            transform_images = transform_images, \n",
    "                                            transform_guidance = transform_guidance)\n",
    "        self.val_dl = DataLoader(self.val_ds, batch_size=self.batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "        if perform_checks:\n",
    "            if not len(self.train_ds):\n",
    "                self.logger.warning(\"The dataloader is empty. No batches to inspect.\")\n",
    "                return None, None\n",
    "\n",
    "            for idx, (images, isds) in enumerate(self.train_ds):\n",
    "                self.logger.info(f\"Inspecting Batch {idx + 1}\")\n",
    "                self.logger.info(f\"Images shape: {images.shape}\")\n",
    "                self.logger.info(f\"ISDs shape: {isds.shape}\")\n",
    "                if idx == 0:\n",
    "                    break\n",
    "\n",
    "    def set_optimizer(self, model_params, optimizer_type=\"Adam\", **kwargs) -> None:\n",
    "        \"\"\"\n",
    "        Method to set up the optimizer.\n",
    "\n",
    "        Args:\n",
    "            model_params (iterable): Parameters of the model to optimize.\n",
    "            optimizer_type (str): Type of optimizer. Default is 'Adam'.\n",
    "            **kwargs: Additional parameters for the optimizer.\n",
    "        \"\"\"\n",
    "        if optimizer_type == \"Adam\":\n",
    "            self.optimizer = torch.optim.Adam(\n",
    "                model_params, \n",
    "                lr=self.lr, \n",
    "                betas=(self.beta1, self.beta2), \n",
    "                weight_decay=self.weight_decay,\n",
    "                **kwargs\n",
    "            )\n",
    "        elif optimizer_type == \"SGD\":\n",
    "            self.optimizer = torch.optim.SGD(\n",
    "                model_params, \n",
    "                lr=self.lr, \n",
    "                momentum=kwargs.get(\"momentum\", 0.9), \n",
    "                weight_decay=self.weight_decay,\n",
    "                **kwargs\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported optimizer type: {optimizer_type}\")\n",
    "\n",
    "        logging.info(f\"Optimizer set to {optimizer_type} with lr={self.lr}, weight_decay={self.weight_decay}\")\n",
    "\n",
    "    def set_scheduler(self, scheduler_type=\"StepLR\", **kwargs) -> None:\n",
    "        \"\"\"\n",
    "        Method to set up the learning rate scheduler.\n",
    "\n",
    "        Args:\n",
    "            scheduler_type (str): Type of learning rate scheduler. Default is 'StepLR'.\n",
    "            **kwargs: Additional parameters for the scheduler.\n",
    "        \"\"\"\n",
    "        if not self.optimizer:\n",
    "            raise ValueError(\"Optimizer must be set before defining the scheduler.\")\n",
    "\n",
    "        if scheduler_type == \"StepLR\":\n",
    "            self.scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "                self.optimizer, \n",
    "                step_size=kwargs.get(\"step_size\", 10), \n",
    "                gamma=kwargs.get(\"gamma\", 0.1)\n",
    "            )\n",
    "        elif scheduler_type == \"ReduceLROnPlateau\":\n",
    "            self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                self.optimizer, \n",
    "                mode=kwargs.get(\"mode\", \"min\"), \n",
    "                factor=kwargs.get(\"factor\", 0.1), \n",
    "                patience=kwargs.get(\"patience\", 10)\n",
    "            )\n",
    "        elif scheduler_type == \"CosineAnnealingLR\":\n",
    "            self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                self.optimizer, \n",
    "                T_max=kwargs.get(\"T_max\", 50), \n",
    "                eta_min=kwargs.get(\"eta_min\", 0)\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported scheduler type: {scheduler_type}\")\n",
    "\n",
    "        logging.info(f\"Scheduler set to {scheduler_type} with parameters: {kwargs}\")\n",
    "\n",
    "    def train_loop(self, epoch: int) -> None:\n",
    "        \"\"\"\n",
    "        Performs the training loop for a single epoch.\n",
    "        \"\"\"\n",
    "        epoch_train_loss = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        self.model.train()\n",
    "        pbar = tqdm(self.train_dl, desc=f\"Training Epoch {epoch}/{self.epochs}\")\n",
    "        for i, data in enumerate(pbar):\n",
    "            imgs, isds = data[\"imgs\"].to(self.device), data[\"isds\"].to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            model_output = self.model(imgs)\n",
    "            loss = self.loss(model_output, isds)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            epoch_train_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            pbar.set_postfix(G_loss=loss.item())\n",
    "\n",
    "        avg_train_loss = epoch_train_loss / num_batches\n",
    "        self.train_loss.append(avg_train_loss)\n",
    "        self.logger.info(f\"Epoch {epoch} - Average Training Loss: {avg_train_loss}\")\n",
    "        return avg_train_loss\n",
    "    \n",
    "    def val_loop(self, epoch: int) -> None:\n",
    "        \"\"\"\n",
    "        Performs the validation loop for a single epoch.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            epoch_val_loss = 0\n",
    "            num_batches = 0\n",
    "\n",
    "            self.model.eval()\n",
    "            pbar = tqdm(self.val_dl, desc=f\"Validation Epoch {epoch}/{self.epochs}\")\n",
    "            for i, data in enumerate(pbar):\n",
    "                imgs, isds = data[\"imgs\"].to(self.device), data[\"isds\"].to(self.device)\n",
    "\n",
    "                model_output = self.model(imgs)\n",
    "                loss = self.loss(model_output, isds)\n",
    "\n",
    "                epoch_val_loss += loss.item()\n",
    "                num_batches += 1\n",
    "                pbar.set_postfix(Val_loss=loss.item())\n",
    "\n",
    "        avg_val_loss = epoch_val_loss / num_batches\n",
    "        self.val_loss.append(avg_val_loss)\n",
    "        self.logger.info(f\"Epoch {epoch} - Average Validation Loss: {avg_val_loss}\")\n",
    "\n",
    "    def save_model_state(self, epoch: int) -> None:\n",
    "        \"\"\"\n",
    "        Saves the current model state to a checkpoint.\n",
    "        \"\"\"\n",
    "        state_save_dir = os.path.join(self.save_dir, \"model_states\")\n",
    "        os.makedirs(state_save_dir, exist_ok=True)\n",
    "\n",
    "        save_path = os.path.join(state_save_dir, f'checkpoint_epoch_{epoch}.pth')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'loss': self.train_loss[-1],\n",
    "        }, save_path)\n",
    "        self.logger.info(f\"Model state saved at epoch {epoch}: {save_path}\")\n",
    "\n",
    "    def save_config(self, config: dict, file_name=\"config.yaml\") -> None:\n",
    "        \"\"\"\n",
    "        Saves the configuration dictionary to a YAML file.\n",
    "        \"\"\"\n",
    "        save_path = os.path.join(self.save_dir, file_name)\n",
    "        try:\n",
    "            with open(save_path, \"w\") as yaml_file:\n",
    "                yaml.dump(config, yaml_file, default_flow_style=False)\n",
    "            self.logger.info(f\"Configuration saved to {save_path}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error saving configuration: {e}\")\n",
    "\n",
    "    def plot_losses(self, epoch: int) -> None:\n",
    "        \"\"\"\n",
    "        Plots and saves the loss vs epoch graph.\n",
    "        \"\"\"\n",
    "        figs_save_dir = os.path.join(self.save_dir, \"loss_figs\")\n",
    "        os.makedirs(figs_save_dir, exist_ok=True)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(range(self.start_epoch, epoch + 1), self.train_loss, label=\"Train Loss\", color=\"b\")\n",
    "        plt.plot(range(self.start_epoch, epoch + 1), self.val_loss, label=\"Validation Loss\", color=\"r\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        fig_path = os.path.join(figs_save_dir, f\"loss_epoch_{epoch}.png\")\n",
    "        plt.savefig(fig_path)\n",
    "        plt.close()\n",
    "        self.logger.info(f\"Loss plot saved: {fig_path}\")\n",
    "\n",
    "    def train_model(self) -> None:\n",
    "        \"\"\"\n",
    "        Trains the model over multiple epochs and returns the final model, optimizer states, and loss history.\n",
    "        \"\"\"\n",
    "        for epoch in range(self.start_epoch, self.start_epoch + self.epochs):\n",
    "            self.train_loop(epoch)\n",
    "            val_loss = self.val_loop(epoch)\n",
    "\n",
    "            # Scheduler step\n",
    "            if isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                self.scheduler.step(val_loss)\n",
    "            else:\n",
    "                self.scheduler.step()\n",
    "\n",
    "            if epoch % 10 == 0 or epoch == self.epochs - 1:\n",
    "                self.plot_losses(epoch)\n",
    "                self.save_model_state(epoch)\n",
    "\n",
    "        return {\n",
    "        \"model_state_dict\": self.model.state_dict(),\n",
    "        \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "        \"train_loss_history\": self.train_loss,\n",
    "        \"val_loss_history\": self.val_loss\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import glob\n",
    "import torch\n",
    "from torch import nn\n",
    "import logging\n",
    "\n",
    "from transformer_dev import VisionTransformer, TrainViT\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"Starting training...\")\n",
    "\n",
    "def load_optimizer_states(optimizer, config):\n",
    "    checkpoint_path = config['pretrained']['checkpoint_path']\n",
    "    if config['pretrained']['load_optim_states'] and os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        if 'optimizer_state_dict' in checkpoint:\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        else:\n",
    "            logger.warning(\"Optimizer state dictionaries not found in checkpoint.\")\n",
    "    return optimizer\n",
    "\n",
    "# Load YAML configuration\n",
    "try:\n",
    "    with open(\"config.yaml\", \"r\") as file:\n",
    "        params = yaml.safe_load(file)\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"The config.yaml file was not found. Please provide a valid path.\")\n",
    "except yaml.YAMLError as e:\n",
    "    raise ValueError(f\"Error parsing YAML file: {e}\")\n",
    "\n",
    "# Validate required keys\n",
    "required_keys = [\"data_dir\", \"num_images\", \"batch_size\", \"epochs\", \"lr\", \"beta1\", \"beta2\", \"run\", \"save_dir\"]\n",
    "for key in required_keys:\n",
    "    if key not in params:\n",
    "        raise ValueError(f\"Missing required configuration key: {key}\")\n",
    "\n",
    "# Extract parameters\n",
    "data_dir = params[\"data_dir\"]\n",
    "paths = glob.glob(os.path.join(data_dir, \"*.tif\"))\n",
    "num_images = params[\"num_images\"]\n",
    "size = params[\"size\"]\n",
    "batch_size = params[\"batch_size\"]\n",
    "epochs = params[\"epochs\"]\n",
    "lr = params[\"lr\"]\n",
    "beta1 = params[\"beta1\"]\n",
    "beta2 = params[\"beta2\"]\n",
    "run = params[\"run\"]\n",
    "save_dir = os.path.abspath(params[\"save_dir\"])\n",
    "start_epoch = params.get(\"start_epoch\", 0)\n",
    "l1_loss = nn.CosineSimilarity()\n",
    "\n",
    "# Model setup\n",
    "model = VisionTransformer(num_layers=12, img_size=size, embed_dim=768, patch_size=16, num_head=8, cnn_embedding=True)\n",
    "model_params = model.parameters()\n",
    "\n",
    "# Initialize training class\n",
    "vit_trainer = TrainViT(size, batch_size, epochs, lr, beta1, beta2, l1_loss, run, start_epoch)\n",
    "vit_trainer.set_train_and_val_paths(paths, num_images)\n",
    "vit_trainer.set_data_loaders()\n",
    "vit_trainer.set_model(model=model)\n",
    "vit_trainer.set_optimizer(model_params=model_params)\n",
    "\n",
    "# Load checkpoint if required\n",
    "if params[\"pretrained\"][\"load_model_state\"]:\n",
    "    vit_trainer.load_state(params[\"pretrained\"][\"checkpoint_path\"])\n",
    "\n",
    "# Save configuration and start training\n",
    "vit_trainer.save_config(config=params)\n",
    "logger.info(f\"Starting Training\")\n",
    "results_dict  = vit_trainer.train_model()\n",
    "\n",
    "logger.info(f\"Final training loss: {results_dict['train_loss_history'][-1]}\")\n",
    "logger.info(f\"Final validation loss: {results_dict['train_loss_history'][-1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS5330",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
