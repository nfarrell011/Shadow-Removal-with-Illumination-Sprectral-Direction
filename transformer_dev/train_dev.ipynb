{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################################################### Packages ###################################################################\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TrainViT:\n",
    "    \"\"\"\n",
    "    Class to pretrain the generator network\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 image_size = 224, \n",
    "                 batch_size = 32, \n",
    "                 epochs = 100, \n",
    "                 lr = 0.0002, \n",
    "                 beta1 = 0.5, \n",
    "                 beta2 = 0.999, \n",
    "                 weight_decay=0, \n",
    "                 loss = nn.L1Loss(), \n",
    "                 run = \"training_run\", \n",
    "                 start_epoch = 0):\n",
    "        \"\"\"\n",
    "        Initializes PreTrainGenerator classes with all default values.\n",
    "        See methods to perform sets.\n",
    "        \"\"\"\n",
    "        self.image_size = image_size\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.weight_decay = weight_decay\n",
    "        self.loss = loss\n",
    "        self.run = run\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.model = None\n",
    "        self.optimizer = None\n",
    "        self.scheduler = None\n",
    "\n",
    "        self.start_epoch = start_epoch\n",
    "        self.epochs = epochs\n",
    "        self.avg_loss = 0\n",
    "\n",
    "        self.train_ds = None\n",
    "        self.val_ds = None\n",
    "        self.train_dl = None\n",
    "        self.val_dl = None\n",
    "\n",
    "        self.train_loss_generator = []\n",
    "        self.val_loss_generator = []\n",
    "\n",
    "        self.val_paths = None\n",
    "        self.train_paths = None\n",
    "\n",
    "    def set_train_and_val_paths(self, data_dir:str, num_images:int) -> None:\n",
    "        \"\"\"\n",
    "        Implement me\n",
    "        \"\"\"\n",
    "        self.train_paths, self.val_paths = select_images(data_dir, num_images)\n",
    "        \n",
    "    def set_model(self, model:callable = None) -> None:\n",
    "        \"\"\"\n",
    "        Set the generator model and optimizer, default is to use a U-Net with a ResNet18 backbone\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def load_state(self, path_to_checkpoint:str) -> None:\n",
    "        \"\"\"\n",
    "        Loads a previous model state\n",
    "        \"\"\"\n",
    "        try:\n",
    "            checkpoint = torch.load(path_to_checkpoint)\n",
    "            self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            self.start_epoch = checkpoint['epoch']\n",
    "            self.avg_loss = checkpoint['loss']\n",
    "            print(f\"Model state loaded successfully!\")\n",
    "        except FileNotFoundError as e:\n",
    "            print(\"Error loading generator weights!\")\n",
    "        return\n",
    "\n",
    "    def set_data_loaders(self, perform_checks:bool = True) -> None:\n",
    "        \"\"\"\n",
    "        Set up the dataloaders\n",
    "        \"\"\"\n",
    "        self.train_ds = IsdDataSet(self.batch_size, paths = self.train_paths, split = \"train\")\n",
    "        self.val_ds = IsdDataSet(self.batch_size, paths = self.val_paths, split = \"val\")\n",
    "        self.train_dl = DataLoader(self.train_ds, batch_size = self.batch_size)\n",
    "        self.val_dl = DataLoader(self.val_ds, batch_size = self.batch_size)\n",
    "\n",
    "        if perform_checks:\n",
    "            data = next(iter(self.train_dl))\n",
    "            Ls, abs_ = data['L'], data['ab']\n",
    "            assert Ls.shape == torch.Size([self.batch_size, 1, self.batch_size, self.batch_size])\n",
    "            assert abs_.shape == torch.Size([self.batch_size, 2, self.batch_size, self.batch_size])\n",
    "            print(Ls.shape, abs_.shape)\n",
    "            print(len(self.train_dl), len(self.val_dl))\n",
    "\n",
    "        return\n",
    "\n",
    "    def train_loop(self, epoch) -> None:\n",
    "        \"\"\"\n",
    "        Performs the train loop tracking train loss\n",
    "        \"\"\"\n",
    "        epoch_train_loss = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        # Train Loop\n",
    "        pbar = tqdm(self.train_dl, desc=f\"Training Epoch {self.start_epoch}/{self.start_epoch + self.epochs}\")\n",
    "        for i, data in enumerate(pbar):\n",
    "            L, abs_ = data[\"L\"], data[\"ab\"]\n",
    "            L, abs_ = L.to(self.device), abs_.to(self.device)\n",
    "    \n",
    "            # Train the generator\n",
    "            self.model.train()\n",
    "            self.optimizer.zero_grad()\n",
    "            generated_abs = self.model(L)\n",
    "    \n",
    "            LOSS = self.loss(generated_abs, abs_) \n",
    "            LOSS.backward()\n",
    "            self.optimizer.step()\n",
    "    \n",
    "            # Accumulate losses\n",
    "            epoch_train_loss += LOSS.item()\n",
    "            num_batches += 1\n",
    "    \n",
    "            # Update progress bar with current loss values\n",
    "            pbar.set_postfix(G_loss=LOSS.item())\n",
    "    \n",
    "        # Average losses for the epoch\n",
    "        avg_train_loss = epoch_train_loss / num_batches\n",
    "        self.train_loss_generator.append(avg_train_loss)\n",
    "        print(f\"The average loss for epoch: {epoch} - {avg_train_loss}\")\n",
    "    \n",
    "        self.scheduler.step(avg_train_loss)\n",
    "\n",
    "    def val_loop(self, epoch) -> None:\n",
    "        \"\"\"\n",
    "        Performs the val loop tracking val loss\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            num_batches = 0\n",
    "            epoch_val_loss = 0\n",
    "            self.model.eval()\n",
    "            \n",
    "            pbar = tqdm(self.val_dl, desc=f\"Validation Epoch {self.start_epoch}/{self.start_epoch + self.epochs}\")\n",
    "            for i, data in enumerate(pbar):\n",
    "                L, abs_ = data[\"L\"], data[\"ab\"]\n",
    "                L, abs_ = L.to(self.device), abs_.to(self.device)\n",
    "    \n",
    "                 # Evaluate the generator\n",
    "                generated_abs = self.model(L)\n",
    "                LOSS = self.loss(generated_abs, abs_) \n",
    "        \n",
    "                # Accumulate losses\n",
    "                epoch_val_loss += LOSS.item()\n",
    "                num_batches += 1\n",
    "        \n",
    "                # Update progress bar with current loss values\n",
    "                pbar.set_postfix(G_loss=LOSS.item())\n",
    "    \n",
    "                # Create the directory to save iamges in\n",
    "                image_save_dir = f\"{str(Path.cwd())}/training_runs/{self.run}/val_images/\"\n",
    "                os.makedirs(image_save_dir, exist_ok=True)\n",
    "                image_save_path = image_save_dir + f\"epoch_{epoch}.png\"\n",
    "                \n",
    "                if epoch % 10 == 0:\n",
    "                    self.plot_batch(L, generated_abs, abs_, show = False, save_path = image_save_path)\n",
    "        \n",
    "        # Calculate average validation loss\n",
    "        avg_val_loss = epoch_val_loss / num_batches\n",
    "        self.val_loss_generator.append(avg_val_loss)\n",
    "        print(f\"Avg Validation Loss: {avg_val_loss}\")\n",
    "        return\n",
    "\n",
    "    def plot_losses(self, epoch) -> None:\n",
    "        \"\"\"\n",
    "        Generates and saves loss versus epoch plot\n",
    "        \"\"\"\n",
    "        # Create fig\n",
    "        figs_save_dir = f\"{str(Path.cwd())}/training_runs/{self.run}/loss_figs/\"\n",
    "        os.makedirs(figs_save_dir, exist_ok=True)\n",
    "        figs_save_path = figs_save_dir + f\"epoch_{epoch}.png\"\n",
    "                \n",
    "        # Ensure the directory exists\n",
    "        epoch_range = range(self.start_epoch, epoch + 1)\n",
    "        plt.plot(epoch_range, self.train_loss_generator, c = \"b\", label = \"Train Loss\")\n",
    "        plt.plot(epoch_range, self.val_loss_generator, c = \"r\", label = \"Val Loss\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(figs_save_path)\n",
    "        plt.close\n",
    "\n",
    "    def save_model_state(self, epoch:int) -> None:\n",
    "        \"\"\"\n",
    "        Saves the current model state\n",
    "        \"\"\"\n",
    "        # Path to model weights location \n",
    "        state_save_dir = f\"/home/farrell.jo/cGAN_grey_to_color/models/generator_train/{self.run}/gen_weights/\"\n",
    "    \n",
    "        # Ensure the directory exists\n",
    "        os.makedirs(state_save_dir, exist_ok=True)\n",
    "    \n",
    "        # Update path with file name\n",
    "        state_save_path = os.path.join(state_save_dir, f'checkpoint_epoch_{epoch}.pth')\n",
    "    \n",
    "        # Save the model weights\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'loss': self.train_loss_generator[-1],\n",
    "        }, state_save_path)\n",
    "        print(f\"Model state saved to: {state_save_path}\")\n",
    "        \n",
    "    def train_model(self) -> None:\n",
    "        \"\"\"\n",
    "        Trains the model\n",
    "        \"\"\"\n",
    "        for epoch in range(self.start_epoch, self.start_epoch + self.epochs):\n",
    "            self.train_loop(epoch)\n",
    "            self.val_loop(epoch)\n",
    "            if epoch % 10 == 1:\n",
    "                self.plot_losses()\n",
    "                self.save_model_state()\n",
    "        \n",
    "    def set_optimizer(self, model_params) -> None:\n",
    "        \"\"\"\n",
    "        Method to set up the optimizer\n",
    "        \"\"\"\n",
    "        self.optimizer = torch.optim.Adam(model_params, lr=self.lr, betas=(self.beta1, self.beta2), weight_decay=self.weight_decay)\n",
    "\n",
    "    def set_scheduler(self) -> None:\n",
    "        \"\"\"\n",
    "        Method to set up the scheduler\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "print(\"This works!!\")\n",
    "if __name__ == \"__main__\":\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Param YAML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for training\n",
    "checkpoint_path: null  # Path to checkpoint file if loading a previous state\n",
    "load_previous_state: false  # Whether to load a previous state\n",
    "data_dir: \"path/to/data\"  # Directory containing .tif images\n",
    "num_images: 10000  # Number of images to use for training\n",
    "size: 256  # Image size\n",
    "batch_size: 32  # Batch size for training\n",
    "epochs: 101  # Number of epochs for training\n",
    "lr: 0.0002  # Learning rate\n",
    "beta1: 0.5  # Beta1 for Adam optimizer\n",
    "beta2: 0.999  # Beta2 for Adam optimizer\n",
    "run: \"test_run_01\"  # Run name for logging and saving checkpoints\n",
    "start_epoch: 0  # Starting epoch\n",
    "\n",
    "pretrained:\n",
    "  checkpoint_path: null  # Path to checkpoint file if loading a previous state\n",
    "  load_model_state: false  # Whether to load the model state\n",
    "  load_optim_states: false  # Whether to load optimizer states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'config.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m optimizer\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Load parameters from YAML\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     35\u001b[0m     params \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(file)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Extract parameters\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/CS5330/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'config.yaml'"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import yaml\n",
    "\n",
    "def load_optimizer_states(optimizer, config):\n",
    "    \"\"\"\n",
    "    Loads the optimizer states for generator and discriminator from the checkpoint\n",
    "    if they exist and if the config specifies to do so.\n",
    "\n",
    "    Args:\n",
    "        optimizer (torch.optim.Optimizer): Optimizer\n",
    "        checkpoint (dict): The loaded checkpoint containing model and optimizer states.\n",
    "        config (dict): Configuration dictionary specifying whether to load optimizer states.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if config['pretrained']['checkpoint_path']:\n",
    "        checkpoint_path = config['pretrained']['checkpoint_path']\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        \n",
    "    if config['pretrained']['load_optim_states']:\n",
    "        try:\n",
    "            if 'optimizer_state_dict' in checkpoint:\n",
    "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            else:\n",
    "                print(\"Optimizer state dictionaries not found in checkpoint.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading optimizer states: {e}\")\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "# Load parameters from YAML\n",
    "with open(\"config.yaml\", \"r\") as file:\n",
    "    params = yaml.safe_load(file)\n",
    "\n",
    "# Extract parameters\n",
    "checkpoint_path = params.get(\"checkpoint_path\")\n",
    "load_previous_state = params.get(\"load_previous_state\", False)\n",
    "data_dir = params[\"data_dir\"]\n",
    "paths = glob.glob(data_dir + \"/*.tif\")\n",
    "num_images = params[\"num_images\"]\n",
    "size = params[\"size\"]\n",
    "batch_size = params[\"batch_size\"]\n",
    "epochs = params[\"epochs\"]\n",
    "lr = params[\"lr\"]\n",
    "beta1 = params[\"beta1\"]\n",
    "beta2 = params[\"beta2\"]\n",
    "l1_loss = nn.L1Loss()\n",
    "run = params[\"run\"]\n",
    "start_epoch = params[\"start_epoch\"]\n",
    "\n",
    "# Select model\n",
    "model = None  # Define or load your model here if needed\n",
    "model_params = model.parameters()\n",
    "\n",
    "# Train model\n",
    "vit_trainer = TrainViT(size, batch_size, epochs, lr, beta1, beta2, l1_loss, run, start_epoch)\n",
    "vit_trainer.set_train_and_val_paths(paths, num_images)\n",
    "vit_trainer.set_data_loaders()\n",
    "vit_trainer.set_model(model=model)\n",
    "vit_trainer.set_optimizer(model_params=model_params)\n",
    "if load_previous_state:\n",
    "    vit_trainer.load_state(checkpoint_path)\n",
    "vit_trainer.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS5330",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
